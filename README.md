# ðŸ“š Spanish BERT Bookâ€‘Category Classifier (2021)

A project that fineâ€‘tunes **BETO** (Spanish BERT, `dccuchile/bert-base-spanish-wwm-uncased`) to classify Spanishâ€‘language book descriptions into **11 academic categories**.

---

## ðŸ—‚  Data Pipeline

| Stage | Details |
|-------|---------|
| **Source** | Google BigQuery table `tlac-vision.book_backend.train_categories` |
| **Cleaning** | â€¢ Dedup titles<br>â€¢ Language check with `langdetect` (keep `es`) |
| **Class balance** | 2â€¯477 rows â†’ class counts 102â€“277 |
| **Splits** | Stratified 70â€¯% / 15â€¯% / 15â€¯% (trainâ€¯/â€¯valâ€¯/â€¯test) |

---

## ðŸ”¢ Preâ€‘processing

| Step | Library | Notes |
|------|---------|-------|
| Tokenisation | `BertTokenizerFast` | max_lenâ€¯=â€¯250, paddingâ€¯=â€¯`max_length` |
| Label Mapping | Dict â†’ 0â€‘10 | 11 classes |
| Class Weights | `compute_class_weight` | for imbalance, passed to `NLLLoss` |

---

## ðŸ§  Model

- **Base**: Frozen BETO encoder (12â€¯layers, 768â€¯dim)
- **Head**: `Linear(768â†’512) + ReLU + Dropout + Linear(512â†’11) + LogSoftmax`
- **Loss**: Weighted `NLLLoss`
- **Optimiser**: `AdamW`, lrâ€¯=â€¯1â€¯eâ€‘5
- **Training**: 50 epochs, best weights saved on lowest valâ€‘loss  
  *(Transformers vâ€¯3.3, PyTorch 1.7 GPU)*

---

## ðŸ“ˆ Results (Test Set)

| Metric | Score |
|--------|-------|
| Accuracy | **49â€¯%** |
| Macroâ€¯F1 | 0.47 |

*Perâ€‘class F1 ranges 0.17â€¯â€“â€¯0.65 (see Colab output).*

---

## ðŸ›   2021 Tech Stack

- Python 3.6â€¯+â€¯PyTorch 1.7 (GPU)
- `transformers`â€¯3.3.1  
- `langdetect`â€¯1.0.8
- Google Colabâ€¯+â€¯BigQuery
